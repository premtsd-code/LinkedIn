input {
  beats {
    port => 5044
  }
}

filter {
  # Handle JSON logs from application_json log_type
  if [log_type] == "application_json" {
    # JSON logs are already parsed by Filebeat
    # Just add timestamp parsing if needed
    if [timestamp] {
      date {
        match => [ "timestamp", "ISO8601" ]
      }
    }
  } else {
    # Parse JSON logs from Docker containers and other sources
    json {
      source => "message"
      skip_on_invalid_json => true
    }

    # Add timestamp parsing
    date {
      match => [ "timestamp", "ISO8601" ]
    }
  }

  # Extract trace ID and span ID from log messages
  # Pattern matches: [traceId-spanId] format from logback
  grok {
    match => {
      "message" => "%{DATA:log_timestamp} \[%{DATA:thread}\] \[(?<traceId>[a-f0-9]{16,32})-(?<spanId>[a-f0-9]{16})\] %{LOGLEVEL:log_level} %{DATA:logger} - %{GREEDYDATA:log_message}"
    }
    tag_on_failure => ["_grokparsefailure_trace"]
  }

  # Alternative pattern for logs without trace ID (fallback)
  if "_grokparsefailure_trace" in [tags] {
    grok {
      match => {
        "message" => "%{DATA:log_timestamp} \[%{DATA:thread}\] \[%{DATA:trace_info}\] %{LOGLEVEL:log_level} %{DATA:logger} - %{GREEDYDATA:log_message}"
      }
      tag_on_failure => ["_grokparsefailure_fallback"]
    }
  }

  # Extract service name from container name or fields
  if [container][name] {
    mutate {
      add_field => { "service_name" => "%{[container][name]}" }
    }
  } else if [fields][service] {
    mutate {
      add_field => { "service_name" => "%{[fields][service]}" }
    }
  } else if [service] {
    mutate {
      add_field => { "service_name" => "%{service}" }
    }
  }

  # Parse log levels from plain text logs
  if [log_type] == "application_text" {
    grok {
      match => { "message" => "%{LOGLEVEL:log_level}" }
      tag_on_failure => ["_grokparsefailure_loglevel"]
    }
  }

  # Add trace correlation fields
  if [traceId] {
    mutate {
      add_field => { "trace_id" => "%{traceId}" }
      add_field => { "span_id" => "%{spanId}" }
      add_field => { "has_trace" => "true" }
    }
  } else {
    mutate {
      add_field => { "has_trace" => "false" }
    }
  }

  # Parse timestamp from log message if available
  if [log_timestamp] {
    date {
      match => [ "log_timestamp", "dd-MM-yyyy HH:mm:ss.SSS", "ISO8601" ]
      target => "@timestamp"
    }
  }

  # Clean up fields
  mutate {
    remove_field => [ "agent", "ecs", "host", "input", "traceId", "spanId" ]
  }
}

output {
  # Uncomment for debugging
  # stdout {
  #   codec => rubydebug
  # }

  opensearch {
    hosts => ["http://opensearch:9200"]
    index => "linkedin-logs-%{+YYYY.MM.dd}"
    ssl => false
    ssl_certificate_verification => false
  }
}
